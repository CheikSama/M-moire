{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import time\n",
    "os.chdir(r\"C:\\Users\\csamassa\\Desktop\\Mémoire\\Nouveau GDN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo=pd.read_csv(\"DEMOCRATIE_ET_CITOYENNETE.csv\", \n",
    "                 sep=\",\",\n",
    "                 #nrows=10,\n",
    "                 usecols=[0,10,2,11,13,14,16,17,19,20,22,23,25,26,27,29,30,31,32,33,34,35,36,37,38,39,40,42,43,44,45,46,47]\n",
    "                 ,dtype={\"authorZipCode\":object}\n",
    "                 )\n",
    "fisc=pd.read_csv(\"LA_FISCALITE_ET_LES_DEPENSES_PUBLIQUES.csv\", \n",
    "                 sep=\",\",\n",
    "                 #nrows=10,\n",
    "                 usecols=[0,10,2,11,12,13,14,15,16,17,18]\n",
    "                 ,dtype={\"authorZipCode\":object}\n",
    "                 )\n",
    "eco=pd.read_csv(\"LA_TRANSITION_ECOLOGIQUE.csv\", \n",
    "                sep=\",\",\n",
    "                #nrows=10,               \n",
    "                usecols=[0,10,2,11,12,14,16,17,18,20,22,23,24,25,26]\n",
    "                ,dtype={\"authorZipCode\":object}\n",
    "                )\n",
    "                \n",
    "org=pd.read_csv(\"ORGANISATION_DE_LETAT_ET_DES_SERVICES_PUBLICS.csv\", \n",
    "                sep=\",\",\n",
    "               #nrows=10,\n",
    "                usecols=[0,10,2,11,13,15,16,19,20,21,24,25,27,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43]\n",
    "                ,dtype={\"authorZipCode\":object}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On rajoute une colonne comportant le thème de chaque question\n",
    "demo.insert(column=\"Thème\",value=\"DEMOCRATIE ET CITOYENNETE\",loc=3)\n",
    "fisc.insert(column=\"Thème\",value=\"LA FISCALITE ET LES DEPENSES PUBLIQUES\",loc=3)\n",
    "eco.insert(column=\"Thème\",value=\"LA TRANSITION ECOLOGIQUE\",loc=3)\n",
    "org.insert(column=\"Thème\",value=\"ORGANISATION DE L'ETAT ET DES SERVICES PUBLIQUES\",loc=3)\n",
    "\n",
    "\n",
    "# On nettoie le début des questions\n",
    "def clean_question(df):\n",
    "    colonnes=df.columns\n",
    "    colonnes1=[re.sub(pattern=r\"\\bQ[A-Za-z0-9]+\\s+\\-\\s\",repl='',string=nom) for nom in colonnes]\n",
    "    return(colonnes1)\n",
    "\n",
    "\n",
    "\n",
    "# On applique tt en même temps\n",
    "demo.columns,fisc.columns,eco.columns,org.columns=clean_question(demo),clean_question(fisc),clean_question(eco),clean_question(org)\n",
    "col1=[\"id\", \"authorZipCode\",\"Thème\"]\n",
    "\n",
    "def empiller(df):\n",
    "    stack_0=df.loc[:, ~df.columns.isin(col1)].stack(dropna=False) # prend les QO (toutes les questions sauf celles de col1)\n",
    "    stack_1=stack_0.reset_index()                                 # On supp l'index pour avoir le level 0 pour la future jointure\n",
    "    stack_2=stack_1.merge(df[col1],left_on=\"level_0\",right_index=True,how=\"left\")\n",
    "    stack_2.columns=[\"idx_0\",\"Question\",\"Réponse\",\"id\",\"authorZipCode\",\"Thème\"] #idx_0 c'est le numéro de la ligne dans le fichier original de chaque thème \n",
    "    stack_2.dropna(inplace=True)\n",
    "    return stack_2\n",
    "\n",
    "\n",
    "demo_1,fisc_1,eco_1,org_1=empiller(demo),empiller(fisc),empiller(eco),empiller(org)\n",
    "\n",
    "del(demo,fisc,eco,org)# On supp les variables inutiles de l'environnement\n",
    "\n",
    "contributions_emp=pd.concat([demo_1,fisc_1,eco_1,org_1],axis=0)   #On met tout dans un même df\n",
    " \n",
    "contributions_emp.reset_index(drop=True,inplace=True)\n",
    "\n",
    "del(demo_1,fisc_1,eco_1,org_1,col1)\n",
    "\n",
    "contributions_emp.drop(columns=\"id\", inplace=True) # On supp la colonne (on a qu'à utiliser idx_0 si on veut la trace des contributions)\n",
    "\n",
    "contributions_emp.to_csv('contributions.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pas besoin de réexecuter la partie du dessus (long à l'execution et gourmand en mémoire), il suffit d'importer le fichier csv qu'on a exporté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "contributions=pd.read_csv('contributions.csv')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.0 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "def compte_group(df,nom,fichier=None,export=False):\n",
    "    resultat=df.loc[df[\"Réponse\"].str.contains(nom,case=False, regex=True)]\n",
    "    ###On va mettre chaque thème dans une feuille différente\n",
    "    ##D'abord on filtre les résultats par thèmes\n",
    "   \n",
    "    if export==True:\n",
    "        resultat_1=resultat.loc[resultat[\"Thème\"]==\"DEMOCRATIE ET CITOYENNETE\"]\n",
    "        resultat_2=resultat.loc[resultat[\"Thème\"]==\"LA FISCALITE ET LES DEPENSES PUBLIQUES\"]\n",
    "        resultat_3=resultat.loc[resultat[\"Thème\"]==\"LA TRANSITION ECOLOGIQUE\"]\n",
    "        resultat_4=resultat.loc[resultat[\"Thème\"]==\"ORGANISATION DE L'ETAT ET DES SERVICES PUBLIQUES\"] # je sais que c'est public mais changer ça est trop chiant à faire pzrce que faudra changer le nom des thèmes (ou y'a la faute aussi)\n",
    "    \n",
    "        writer = pd.ExcelWriter(fichier+'.xlsx', engine='xlsxwriter')\n",
    "    \n",
    "        resultat_1.to_excel(writer, sheet_name=\"DEMOCRATIE\")\n",
    "        resultat_2.to_excel(writer, sheet_name=\"FISCALITE\")\n",
    "        resultat_3.to_excel(writer, sheet_name=\"TRANSITION_ECOLOGIQUE\")\n",
    "        resultat_4.to_excel(writer, sheet_name=\"ORGANISATION_DE_LETAT\") \n",
    "    \n",
    "        writer.save()\n",
    "    return(resultat)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va prendre un exemple pour essayer notre code: toutes les contributions du GDN qui contiennent les mots pandémie, épidémie sras, coronavirus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 68.04011678695679 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "corona=compte_group(contributions,r\"\\bpand[e-é]mi[a-z]\\b|\\b[e-é]pid[e-é]mie\\b|\\bsras\\b|\\bcoronavirus\\b\")\n",
    "\n",
    "aleo=corona[\"Réponse\"].apply(nltk.sent_tokenize)\n",
    "\n",
    "#DF series.apply est plus rapide que df.apply\n",
    "\n",
    "#On ne  prend que les contributions de plus d'une phrase\n",
    "essai=pd.DataFrame(aleo.loc[aleo.apply(len)>1].apply(pd.Series).stack()).reset_index()#la fonction series fait que le séparateur devient la virgule entre chaque éléments de la liste, le stack fait qu'on les empile, on a un multi index où chaque index de level 0= numéro de la contribution, level 1= numéro de la phrase dans la contribution\n",
    "\n",
    "#On ajoute le nombre de phrases de chaque contributions\n",
    "essai_gpby=essai.groupby(by=\"level_0\",as_index=False)[0].count()\n",
    "\n",
    "essai=essai.merge(essai_gpby,on=\"level_0\")\n",
    "\n",
    "\n",
    "essai.columns=[\"level_0\",\"nb_sent\",\"sent\",\"nb_sent_total\"]\n",
    "contain=essai.loc[essai[\"sent\"].str.contains(r\"\\bpand[e-é]mi[a-z]\\b|\\b[e-é]pid[e-é]mie\\b|\\bsras\\b|\\bcoronavirus\\b\",regex=True,case=False)]\n",
    "\n",
    "# On met dans un dictionnaire l'index de chaque phrase contenant notre pattern\n",
    "dico_lvl_contain=dict(zip(contain.index,zip(contain[\"nb_sent\"],contain[\"nb_sent_total\"])))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque phrase qui contient les mots qu'on veut, on prend celle d'avant et celle d'après. \n",
    "Si jamais la phrase qui contient les patterns est la première, python va renvoyer une erreur lorsqu'on va lui demander \n",
    "de prendre la phrase d'avant vu qu'il n'y a rien avant, viceversa si c'est après. \n",
    "Pour résoudre cela, on va dire à python d'exclure la première lorsqu'on lui demandera de prendre les phrases x-1 et la dernière phrase quand on lui demande de prendre les phrases x+1 (encore une fois si y'a rien après x on va avoir une erreur index out of bounds). \n",
    "On a selectionné dans une autre opérationles phrases qui contiennent le pattern, cette opération a pour but de prendre x-1 et x+1 pas x. \n",
    "Si la première phrase contient le pattern, python ne va prendre que celle qui la suit, et si dernière phrase contient le pattern, python ne va prendre que celle qui la précède, \n",
    "Si la première et la deuxième phrase contiennent le patern, python va prendre celle qui la suit (x+1), et la ligne suivante python va de nouveau prendre la première (x-1, qui contient le pattern),  et la troisème (x+1), la deuxième étant x sur cette ligne (x+1 la ligne précédente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.03500008583068848 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "idx_avant=[[k-1,k,v] for (k,v) in dico_lvl_contain.items() if v[0]>0] #prend la phrase d'avant si la phrase  (celle qui matche le pattern) n'est pas la première de la contribution, donc d'index supérieur à 0\n",
    "phrase_avant=essai.loc[[x[0] for x in idx_avant],]\n",
    "phrase_avant[\"id_x\"]=essai.loc[[x[1] for x in idx_avant],].index # On ajoute l'index des phrases qui contiennent la phrase du patern(celle d'après du coup si répond aux conditions du for)\n",
    "phrase_avant.columns=[\"level_0\",\"nb_sent_av\", \"sent_av\",\"nb_sent_total\",\"id_x\"]\n",
    "\n",
    "idx_apres=[[k+1,k,v] for (k,v) in dico_lvl_contain.items() if v[0]<(v[1]-1)] # # prend la phrase d'après si la phrase n'est pas la dernière de la contribution, donc d'index inférieure au nombre de phrases dans la contribution. on ajoute moins 1 parce que v[1] c'est la taille par ex 20 et v[0] c'est l'index (0:19) donc faut mettre v[1]-1 pour que ça corresponde\n",
    "\n",
    "phrase_apres=essai.loc[[x[0] for x in idx_apres],]\n",
    "phrase_apres[\"id_x\"]=essai.loc[[x[1] for x in idx_apres],].index #On ajoute l'index des phrases du pattern (celle d'avant du coup si matche les conditions)\n",
    "phrase_apres.columns=[\"level_0\",\"nb_sent_ap\", \"sent_ap\",\"nb_sent_total\",\"id_x\"]\n",
    "\n",
    "contain=contain.rename_axis('id_x').reset_index() #On ajoute la colonne de l'id pour la jointure\n",
    "essai_final=contain.merge(phrase_avant, on=\"id_x\", how=\"outer\").merge(phrase_apres,on=\"id_x\",how=\"outer\") #On fait une union des trois dataframes\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>sent_av</th>\n",
       "      <th>sent_ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lutte contre EPIDEMIE sida, diminution nb d’av...</td>\n",
       "      <td>Que tous les profs les informent de l’existenc...</td>\n",
       "      <td>Tous les enfants ont les mêmes droits.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prévue pour faire face aux risques d'épidémie ...</td>\n",
       "      <td>qui est une injustice sociale exorbitante au r...</td>\n",
       "      <td>Elle donne donc lieu à une immigration sanitai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Si leur dossier est recevable parce que la gue...</td>\n",
       "      <td>Ensuite la langue, les lois, les DEVOIRS.</td>\n",
       "      <td>Si comme dirait le Premier Ministre Néozélanda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Il faut pourvoir distinguer les asiles d'urgen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pour les autres, il faut faire appliquer des c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comme l'épidémie n'a pas eu lieu, les Français...</td>\n",
       "      <td>Par exemple, l'histoire du vaccin pandémique.</td>\n",
       "      <td>Par contre, il faut que l'état soit exemplaire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>le taux d’absentéisme pour raisons de santé, q...</td>\n",
       "      <td>Le rétablissement du jour de carence suffirait...</td>\n",
       "      <td>le problème tient au statut très avantageux de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>aussi des congés, une épidémie et des services...</td>\n",
       "      <td>ça ne se passe pas si aml que ça, sauf que de ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Lorsqu’on a besoin d’une consultation simple (...</td>\n",
       "      <td>Les cabinets de médecins sont débordés et la p...</td>\n",
       "      <td>Il s’agirait d’un niveau « 1 » qui desorgorger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Les pénuries de médicaments de plus en plus fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Il faut assurer notre indépendance dans ce dom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>les services centralisé de tous la Républiques...</td>\n",
       "      <td>Une chaine crypté d'accès à un espace concitoy...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  sent  \\\n",
       "0    Lutte contre EPIDEMIE sida, diminution nb d’av...   \n",
       "1    Prévue pour faire face aux risques d'épidémie ...   \n",
       "2    Si leur dossier est recevable parce que la gue...   \n",
       "3    Il faut pourvoir distinguer les asiles d'urgen...   \n",
       "4    Comme l'épidémie n'a pas eu lieu, les Français...   \n",
       "..                                                 ...   \n",
       "163  le taux d’absentéisme pour raisons de santé, q...   \n",
       "164  aussi des congés, une épidémie et des services...   \n",
       "165  Lorsqu’on a besoin d’une consultation simple (...   \n",
       "166  Les pénuries de médicaments de plus en plus fr...   \n",
       "167  les services centralisé de tous la Républiques...   \n",
       "\n",
       "                                               sent_av  \\\n",
       "0    Que tous les profs les informent de l’existenc...   \n",
       "1    qui est une injustice sociale exorbitante au r...   \n",
       "2            Ensuite la langue, les lois, les DEVOIRS.   \n",
       "3                                                  NaN   \n",
       "4        Par exemple, l'histoire du vaccin pandémique.   \n",
       "..                                                 ...   \n",
       "163  Le rétablissement du jour de carence suffirait...   \n",
       "164  ça ne se passe pas si aml que ça, sauf que de ...   \n",
       "165  Les cabinets de médecins sont débordés et la p...   \n",
       "166                                                NaN   \n",
       "167  Une chaine crypté d'accès à un espace concitoy...   \n",
       "\n",
       "                                               sent_ap  \n",
       "0               Tous les enfants ont les mêmes droits.  \n",
       "1    Elle donne donc lieu à une immigration sanitai...  \n",
       "2    Si comme dirait le Premier Ministre Néozélanda...  \n",
       "3    Pour les autres, il faut faire appliquer des c...  \n",
       "4    Par contre, il faut que l'état soit exemplaire...  \n",
       "..                                                 ...  \n",
       "163  le problème tient au statut très avantageux de...  \n",
       "164                                                NaN  \n",
       "165  Il s’agirait d’un niveau « 1 » qui desorgorger...  \n",
       "166  Il faut assurer notre indépendance dans ce dom...  \n",
       "167                                                NaN  \n",
       "\n",
       "[168 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essai_final.loc[:,[\"sent\",\"sent_av\",\"sent_ap\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
